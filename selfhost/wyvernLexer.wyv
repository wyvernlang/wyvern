module def wyvernLexer(js:Dyn, regexUtils:Dyn)

import metadata lexing
import wyvern.collections.llist
import wyvern.runtime

type List = llist.LinkedList

/************** Tokens ***************/

type Token
    val "type":String
    val value:String
    val line:Int
    val col:Int

def Token(t:String, value:String, line:Int, col:Int):Token = new
    val "type":String = t
    val value:String = value
    val line:Int = line
    val col:Int = col


/************** First Level Lexer ***************/

val lowLevelLexer : lexing.Lexer = ~
        WS:         /[ \t]+/,
        logline:    {match: /\n/, lineBreaks: true},
        identifier: {match: /[a-zA-Z][a-zA-Z0-9_]*/, type: moo.keywords({ val : 'val', def : 'def' })},
        lparen:     '(',
        rparen:     ')',
        lbrack:     '[',
        rbrack:     ']',
        darrow:     '=>',
        arrow:      '->',
        colon:      ':',
        eq:         '=',
        linecont:   '\\',
        plus:       '+',
        minus:      '-',
        times:      '*',
        divide:     '/',
        mod:        '%',
        integer:    /\d+/,

val startLexerState = lowLevelLexer.save()
        
def lowerLexOrdinaryLine(input:String):List[Dyn]
    var tokens : List[Dyn] = llist.Nil[Dyn]()
    lowLevelLexer.reset(input, startLexerState)
    var token : Dyn = lowLevelLexer.next()
    //js.log("called lowerLexOrdinaryLine")
    def loop():Unit
        if (!js.isUndefined(token))
            tokens = tokens.push(token)
            token = lowLevelLexer.next()
            loop()
    loop()
    val result = tokens.reverse()
    result

// converts the string into a token.  We assume the string does not include a newline.
// TODO: return token with correct line/column
def lexIndentedLine(input:String):Token = Token("indentedLine", input, -1, -1)

// true if the string contains only whitespace characters    
def allWhitespace(input:String):Boolean
    val lineMatch = regexUtils.doMatch(input, "[ \\t]*")
    if (lineMatch.found)
        lineMatch.after == ""
      else
        false
    
/************** Second Level Lexer ***************/
    
datatype LexerState
    Indent(level:String)
    LParen()
    RParen()
    LBrack()
    RBrack()
    Block(text:String)
    LineCont()
    OpenComment()
    DontCare()

var lexerState:List[LexerState] = llist.Nil[LexerState]()
    
val NO_INDENT = "NONE"

def getCurrentIndent() : String
    def findIndent(l:List[LexerState]):String = match l:
        n:llist.Nil => NO_INDENT
        c:llist.Cons => match c.value:
            i:Indent => i.level
            default  => findIndent(c.next)
    findIndent(lexerState)

def getIndent(input:String) : String
    val lineMatch = regexUtils.doMatch(input, "[ \\t]+")
    if (lineMatch.found)
        lineMatch.matched
      else
        ""

def isStrictSubstring(s1:String,s2:String):Boolean
    if (s1.length() < s2.length())
        val s2part = s2.substring(0, s1.length())
        s1 == s2part
      else
        false
        
def setIndent(lineIndent:String):Unit
    match lexerState:
        c:llist.Cons =>
            lexerState = lexerState.drop(1).get()
            match c.value:
                i:Indent =>
                    lexerState = lexerState.push(Indent(lineIndent))
                default =>
                    setIndent(lineIndent)
                    lexerState = lexerState.push(c.value)
        default => unit

// returns a new pending list with dedents prepended
def addDedents(lineIndent:String, pending:List[Dyn], tokens:List[Token]):List[Dyn]
    match lexerState:
        c:llist.Cons =>
            lexerState = lexerState.drop(1).get()
            match c.value:
                i:Indent => addDedents(lineIndent, pending.push(Token("dedent","", 0, 0)), tokens)
                l:LParen => pending
                l:LBrack => pending
        n:llist.Nil =>
            runtime.fail("didn't match indent/dedent")

def allWhitespaceTokens(toks:List[Token]):Boolean = match toks:
    c:llist.Cons =>
        if (c.value."type" == "WS")
            allWhitespaceTokens(c.next)
          else
            false
    default => true

// passed input one line at a time, not including the terminating \n
def lexLine(input:String):List[Dyn]
    var pending:List[Dyn] = llist.Nil[Dyn]() // in reverse order
    val topState = lexerState.nth(0).getOrElse(() => DontCare())
    // TODO: bug in codegen means have to let-bind topState
    match topState:
        b:Block =>
            var currentIndent : String = getCurrentIndent()
            if (currentIndent == "NONE")
                currentIndent = ""
            val lineIndent = getIndent(input)
            if (isStrictSubstring(currentIndent,lineIndent) || allWhitespace(input))
                // extending the block
                val token = lexIndentedLine(input)
                lexerState = lexerState.drop(1).get()
                lexerState = lexerState.push(Block(b.text + token.value))
                pending // empty
              else
                // ending the block
                pending = pending.push(b)
                lexerState = lexerState.drop(1).get()
                lexOrdinaryLine(pending, input)
        default =>
            lexOrdinaryLine(pending, input)

def lexOrdinaryLine(pending_:List[Dyn], input:String):List[Dyn]
    val tokens = lowerLexOrdinaryLine(input)
    var pending:List[Dyn] = pending_ // in reverse order
    val topState = lexerState.nth(0).getOrElse(() => DontCare())
    if (allWhitespace(input))
        // if lexerState.top()==LINECONTINUATION && tokens.last != LINECONTINUATION
        match topState:
            l:LineCont =>
                if (!(tokens.nth(tokens.size()-1).map[String](x:Token => x."type").getOrElse(() => "") == "linecont"))
                    lexerState = lexerState.drop(1).get()
            default    =>
                unit
        pending.reverse().append(tokens)
      else
        match topState:
            l:LineCont =>
                lexerState = lexerState.drop(1).get()
                handleLine(pending, tokens)
            l:LParen => handleLine(pending, tokens)
            l:LBrack => handleLine(pending, tokens)
            default =>
                var currentIndent : String = getCurrentIndent()
                val lineIndent = getIndent(input)
                if (currentIndent == NO_INDENT)
                    setIndent(lineIndent)
                    currentIndent = ""
                if (currentIndent == lineIndent)
                    // new line at same indent level
                    // TODO: fix line/column here
                    pending = pending.push(Token("logline","\n",0,0))
                    handleLine(pending, tokens)
                  elif (isStrictSubstring(lineIndent,currentIndent))
                    // one or more dedents
                    addDedents(lineIndent, pending, tokens)
                  else
                    // lineIndent > currentIndent
                    handleLine(pending, tokens)
            
def handleLine(pending_:List[Dyn], tokens:List[Token]):List[Dyn]
    //inLine = true
    var toks:List[Dyn] = tokens
    printTokens(toks)
    var pending:List[Dyn] = pending_ // in reverse order
    
    def computeDedents(matchingType:String):Unit
        val top = lexerState.nth(0).get()
        lexerState = lexerState.drop(1).get()
        val errorString = "didn't match token " + matchingType
        match top:
            i:Indent =>
                pending = pending.push(Token("dedent", "", 0, 0))
                computeDedents(matchingType)
            l:LParen => runtime.assertion(errorString, matchingType == "lparen")
            l:LBrack => runtime.assertion(errorString, matchingType == "lbrack")
            default  => runtime.fail(errorString)
    
    def loop():Unit
      match toks:
        c:llist.Cons => 
            toks = c.next
            val t:Token = c.value
            val kind = t."type"
            if (kind == "lparen")
                lexerState = lexerState.push(LParen())
              elif (kind == "lbrack")
                lexerState = lexerState.push(LBrack())
              elif (kind == "rparen")
                computeDedents("lparen")
              elif (kind == "rbrack")
                computeDedents("lbrack")
              elif (kind == "colon")
                if (allWhitespaceTokens(toks))
                    lexerState = lexerState.push(Block(""))
              elif (kind == "eqarrow")
                if (allWhitespaceTokens(toks))
                    lexerState = lexerState.push(Indent(NO_INDENT))
              else
                unit
            pending = pending.push(c.value)
            loop()
        n:llist.Nil => unit
    
    loop()
    // if ends with linecont, set the flag and don't add linecont
    match pending:
        c:llist.Cons =>
            val t : Token = c.value
            if (t."type" == "linecont")
                pending = c.next
                lexerState = lexerState.push(LineCont())

    // return pending (reversed)
    pending.reverse()


// WITH CONTINUATION: lex a line and return whether it is a complete logical line or not (store internally if not, return if so)
        
// lex multiple lines to return a combined list (uses module-global variable, same as above)
def lexLines(input:String):List[Dyn]
    val lineMatch = regexUtils.doMatch(input, "[^\\n]*")
    if (lineMatch.found)
        js.log("reading line " + lineMatch.matched)
        val firstTokens = lexLine(lineMatch.matched)
        printTokens(firstTokens)
        if (lineMatch.after == "")
            firstTokens
          else
            val newlineMatch = regexUtils.doMatch(lineMatch.after, "\\n")
            val restTokens = lexLines(newlineMatch.after)
            firstTokens.append(restTokens)
      else
        llist.Nil[Dyn]()
    //js.log(newlineMatch.found)
    //js.log(newlineMatch.matched)
    //js.log(newlineMatch.after)

def printToken(t:Dyn):Unit = js.log(t."type")

def printTokens(tokens:List[Dyn]):Unit
    tokens.do(x => printToken(x))

resource type IncrementalLexer
    def addLine(input:String):option.Option[lexing.Lexer]

    /*
// TODO: revise to work with lineCont
def incrementalLexer():IncrementalLexer
    // TODO: make all the state above local
    new
        var tokens : List[Dyn] = llist.Nil[Dyn]()
        def addLine(input:String):option.Option[lexing.Lexer]
            this.tokens = this.tokens.append(lexLine(input))
            if (lineCont)
                option.None[lexing.Lexer]()
              else
                option.Some[lexing.Lexer](initLexer(this.tokens))
*/

def makeLexer():lexing.Lexer
    initLexer(llist.Nil[Dyn]())
    
def initLexer(toks : List[Dyn]):lexing.Lexer
    var tokens : List[Dyn] = toks
    new
        def next():Dyn = match tokens:
            c:llist.Cons =>
                           tokens = c.next
                           val token:Dyn = c.value
                           //js.log("lexer returning " + token.value)
                           c.value
            n:llist.Nil => js.getUndefined()
        def save():Dyn = js.log("called save\n")
        def reset(chunk:String, info:Dyn):Unit
            js.log("called reset\n")
            tokens = lexLines(chunk).filter((t:Dyn) => !js.equalsJS("WS", t."type"))
            //tokens.do((t:Dyn) => printToken(t))
        def formatError(token:Dyn):String
            js.log("called formatError")
            js.log(token)
            "this is an error"
        def has(name:String):Boolean = lowLevelLexer.has(name)
